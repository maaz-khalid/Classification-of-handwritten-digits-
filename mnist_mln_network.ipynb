{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_mln_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MvErumT0n0_-"
      },
      "source": [
        "# Classification of handwritten digits using MLN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zh0uH8bDn1AE"
      },
      "source": [
        "# MNIST Dataset\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" title=\"MNIST dataset\" align=\"center\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1K6Im4RYn1AK"
      },
      "source": [
        "# Problem\n",
        "Classify handwritten digits from 0 - 9. <br>\n",
        "Each image is 28x28 pixels\n",
        "\n",
        "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot.png\" title=\"\" align=\"center\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EVex4puqn1AO"
      },
      "source": [
        "# Understanding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "alqmfbOIn1AR",
        "colab": {}
      },
      "source": [
        "# MNIST data is present in the keras library. You may load it from there\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_samples, train_labels), (test_samples, test_labels) = mnist.load_data()\n",
        "# Training samples "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3CNRCPbrn1Ae"
      },
      "source": [
        "### Shape of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pAn6o3Vn1Ag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "00441aef-5654-46ea-c653-f7126c68aadb"
      },
      "source": [
        "print(train_samples.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_samples.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ubf7aJPIn1Ax"
      },
      "source": [
        "### Range of Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-jiF1J8Jn1A0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0161f343-870a-4715-a8bd-1fd17ff953dc"
      },
      "source": [
        "import numpy as np\n",
        "np.amax(train_samples) # Max value"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mu18byDmn1A-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e5181ba-be45-4f2d-e735-d1874995bd06"
      },
      "source": [
        "np.amin(train_samples) # Min Value"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_OkrzUFQn1BI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "87efcfbb-ab95-47f3-ce06-c80bf58316c6"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pixels = train_samples[0] # Shape (28, 28)\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "print('Label of image is', train_labels[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label of image is 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6JiZgztn1BP"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7hUHie4_n1BQ"
      },
      "source": [
        "### Normalize inputs to (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iGKZASBBn1BS",
        "colab": {}
      },
      "source": [
        "# Convert data type from uint8 to float32\n",
        "train_samples = train_samples.astype('float32')\n",
        "test_samples = test_samples.astype('float32')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gbaIejYPn1BX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c4c42bf-976a-4d6f-f4f6-972b617daef0"
      },
      "source": [
        "# Normalize inputs to (0,1)\n",
        "train_samples = train_samples/255.\n",
        "test_samples = test_samples/255.\n",
        "np.amax(train_samples) # max value has become 1.0\n",
        "print(train_samples.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0klvh6HMn1Be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a920c71-2b6a-4f34-fb69-4897952b3ef3"
      },
      "source": [
        "## Reshape input to be a column vector\n",
        "train_samples = train_samples.reshape(train_samples.shape[0], 28*28)\n",
        "print(train_samples.shape)\n",
        "test_samples = test_samples.reshape(test_samples.shape[0], 28*28)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzvfaeh9n1Bj"
      },
      "source": [
        "### Convert outputs to 1-hot vectors\n",
        "\\begin{equation*}\n",
        "Eg: 5 \\rightarrow [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kCxrh0-nn1Bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3b41e42-1072-41c4-d9e6-a16cdf63d59d"
      },
      "source": [
        "# keras has a utility function for this\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "# example\n",
        "train_labels[0] # label = 5"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2_Pt8JB8n1Bq"
      },
      "source": [
        "# Network Architecture\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1m2jgscTgKlvtzj757I9YMJE2sqNXmMMy\" title=\"\" align=\"center\" width=\"50%\" height=\"50%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aceZEJRzn1Bs"
      },
      "source": [
        "### Softmax Activation Function\n",
        "In the Dense (Fully Connected) layer, we use a softmax activation function\n",
        "\\begin{align}\n",
        "\\sigma(x_j) = \\frac{e^{x_j}}{\\sum_{i}e^{x_i}}\n",
        "\\end{align}\n",
        "\n",
        " The softmax function is a function that takes as input a vector of K real numbers, and normalizes it into a probability distribution consisting of K probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "amqRJpZun1Bt",
        "colab": {}
      },
      "source": [
        "# Layer definitions\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "input_layer = Input(shape = train_samples.shape[1:])\n",
        "hidden_layer = Dense(512, activation = 'sigmoid',)(input_layer)\n",
        "output_layer = Dense(10, activation = 'softmax')(hidden_layer)\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VBVFR5ran1By"
      },
      "source": [
        "Loss is Categorical Crossentropy\n",
        "\n",
        "\\begin{align}\n",
        "L(t,p) = -\\sum_{x}t(x)log(p(x))\n",
        "\\end{align}\n",
        "\n",
        "where  𝑥  ranges over the elements of the output vector\n",
        "\n",
        "\\begin{align}\n",
        "t \\rightarrow \\text{true probability distribution} \\\\\n",
        "p \\rightarrow \\text{predicted probability distribution}\n",
        "\\end{align}\n",
        "In our case, $t$ is always a delta function. \n",
        "For eg., for label = 5,<br>\n",
        "$t(x) = 1$ if $x = 5$ and 0 otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PiZKWdx5n1B0"
      },
      "source": [
        "Weight update Rule\n",
        "\n",
        "\\begin{align}\n",
        "W' \\leftarrow W - \\eta\\frac{\\partial L}{\\partial W}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iN6BITwtn1B1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "12aa97e5-6b99-4431-c70c-1dee50738e49"
      },
      "source": [
        "# Model definition\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-2Sfsxtn1B7",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc9bc3e8-2c68-4588-e8ba-15f1e6a0faca"
      },
      "source": [
        "history = model.fit(train_samples, train_labels, validation_split = 0.1, epochs=100, batch_size=200)\n",
        "# Use 10% of samples for validation, validation_split is the relevant parameter\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.8605 - val_loss: 0.2577 - val_accuracy: 0.9307\n",
            "Epoch 2/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2833 - accuracy: 0.9192 - val_loss: 0.2104 - val_accuracy: 0.9425\n",
            "Epoch 3/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2346 - accuracy: 0.9331 - val_loss: 0.1751 - val_accuracy: 0.9515\n",
            "Epoch 4/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1990 - accuracy: 0.9422 - val_loss: 0.1570 - val_accuracy: 0.9567\n",
            "Epoch 5/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9516 - val_loss: 0.1355 - val_accuracy: 0.9625\n",
            "Epoch 6/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9583 - val_loss: 0.1292 - val_accuracy: 0.9643\n",
            "Epoch 7/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9639 - val_loss: 0.1179 - val_accuracy: 0.9673\n",
            "Epoch 8/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9684 - val_loss: 0.1096 - val_accuracy: 0.9695\n",
            "Epoch 9/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 0.0937 - val_accuracy: 0.9718\n",
            "Epoch 10/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9756 - val_loss: 0.0884 - val_accuracy: 0.9732\n",
            "Epoch 11/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9794 - val_loss: 0.0875 - val_accuracy: 0.9745\n",
            "Epoch 12/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.0836 - val_accuracy: 0.9742\n",
            "Epoch 13/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.9841 - val_loss: 0.0823 - val_accuracy: 0.9748\n",
            "Epoch 14/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9862 - val_loss: 0.0781 - val_accuracy: 0.9762\n",
            "Epoch 15/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9880 - val_loss: 0.0744 - val_accuracy: 0.9747\n",
            "Epoch 16/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9899 - val_loss: 0.0707 - val_accuracy: 0.9785\n",
            "Epoch 17/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9914 - val_loss: 0.0689 - val_accuracy: 0.9790\n",
            "Epoch 18/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9929 - val_loss: 0.0675 - val_accuracy: 0.9785\n",
            "Epoch 19/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9936 - val_loss: 0.0696 - val_accuracy: 0.9792\n",
            "Epoch 20/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.0673 - val_accuracy: 0.9795\n",
            "Epoch 21/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.0662 - val_accuracy: 0.9793\n",
            "Epoch 22/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.0672 - val_accuracy: 0.9797\n",
            "Epoch 23/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.0655 - val_accuracy: 0.9803\n",
            "Epoch 24/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.0655 - val_accuracy: 0.9803\n",
            "Epoch 25/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 0.0653 - val_accuracy: 0.9813\n",
            "Epoch 26/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 0.0637 - val_accuracy: 0.9817\n",
            "Epoch 27/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9813\n",
            "Epoch 28/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.0653 - val_accuracy: 0.9810\n",
            "Epoch 29/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0631 - val_accuracy: 0.9820\n",
            "Epoch 30/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.0657 - val_accuracy: 0.9817\n",
            "Epoch 31/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9815\n",
            "Epoch 32/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9825\n",
            "Epoch 33/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0632 - val_accuracy: 0.9827\n",
            "Epoch 34/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0666 - val_accuracy: 0.9813\n",
            "Epoch 35/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0657 - val_accuracy: 0.9818\n",
            "Epoch 36/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0644 - val_accuracy: 0.9820\n",
            "Epoch 37/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9815\n",
            "Epoch 38/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9833\n",
            "Epoch 39/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0724 - val_accuracy: 0.9812\n",
            "Epoch 40/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9823\n",
            "Epoch 41/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9822\n",
            "Epoch 42/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9825\n",
            "Epoch 43/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9822\n",
            "Epoch 44/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 8.9016e-04 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9818\n",
            "Epoch 45/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 8.0485e-04 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9825\n",
            "Epoch 46/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 6.6644e-04 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9832\n",
            "Epoch 47/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 6.2133e-04 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9835\n",
            "Epoch 48/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 5.6627e-04 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9825\n",
            "Epoch 49/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 4.7707e-04 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9828\n",
            "Epoch 50/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 4.0546e-04 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9838\n",
            "Epoch 51/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.5152e-04 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9830\n",
            "Epoch 52/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.1734e-04 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9832\n",
            "Epoch 53/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.9439e-04 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9825\n",
            "Epoch 54/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.6335e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9835\n",
            "Epoch 55/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.1018e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9830\n",
            "Epoch 56/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.8295e-04 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9835\n",
            "Epoch 57/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.6130e-04 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9833\n",
            "Epoch 58/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9835\n",
            "Epoch 59/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9833\n",
            "Epoch 60/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.1114e-04 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9825\n",
            "Epoch 61/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 9.8056e-05 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9833\n",
            "Epoch 62/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 8.5949e-05 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9833\n",
            "Epoch 63/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 7.6819e-05 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9828\n",
            "Epoch 64/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 6.5817e-05 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9833\n",
            "Epoch 65/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 6.4613e-05 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9832\n",
            "Epoch 66/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 5.2018e-05 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9835\n",
            "Epoch 67/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 4.4703e-05 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9835\n",
            "Epoch 68/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.8855e-05 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9832\n",
            "Epoch 69/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.4694e-05 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9835\n",
            "Epoch 70/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.1388e-05 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9832\n",
            "Epoch 71/100\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 2.6929e-05 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9833\n",
            "Epoch 72/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.3636e-05 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9840\n",
            "Epoch 73/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.1180e-05 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9833\n",
            "Epoch 74/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1403 - val_accuracy: 0.9732\n",
            "Epoch 75/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0885 - val_accuracy: 0.9818\n",
            "Epoch 76/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 8.3771e-05 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9830\n",
            "Epoch 77/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 5.1504e-05 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9828\n",
            "Epoch 78/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 4.2500e-05 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9828\n",
            "Epoch 79/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.6942e-05 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9830\n",
            "Epoch 80/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 3.2835e-05 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9830\n",
            "Epoch 81/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.9706e-05 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9827\n",
            "Epoch 82/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.7239e-05 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9828\n",
            "Epoch 83/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.5056e-05 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9827\n",
            "Epoch 84/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.3077e-05 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9828\n",
            "Epoch 85/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.1540e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9825\n",
            "Epoch 86/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 2.0110e-05 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9827\n",
            "Epoch 87/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.8794e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9828\n",
            "Epoch 88/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.7585e-05 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9828\n",
            "Epoch 89/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.6610e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9830\n",
            "Epoch 90/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.5579e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9832\n",
            "Epoch 91/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.4677e-05 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9832\n",
            "Epoch 92/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.3851e-05 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9835\n",
            "Epoch 93/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.3087e-05 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9837\n",
            "Epoch 94/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.2331e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9835\n",
            "Epoch 95/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.1681e-05 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9833\n",
            "Epoch 96/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.1018e-05 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9835\n",
            "Epoch 97/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.0360e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9835\n",
            "Epoch 98/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 9.7595e-06 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9833\n",
            "Epoch 99/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 9.2346e-06 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9837\n",
            "Epoch 100/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 8.6523e-06 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B12vN44Ln1CF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4fb0f756-68cd-448d-8c2f-b9e4d6fa522c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "loss, accuracy = model.evaluate(test_samples, test_labels,verbose=0)  # Evaluate the model\n",
        "print('Accuracy :%0.3f'%accuracy)\n",
        "\n",
        "pred_labels = model.predict(test_samples)\n",
        "cm = confusion_matrix(test_labels.argmax(axis=1), pred_labels.argmax(axis=1))\n",
        "print(cm )\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :0.982\n",
            "[[ 970    0    1    1    1    1    3    1    1    1]\n",
            " [   0 1124    3    1    0    1    2    1    3    0]\n",
            " [   5    1 1010    2    1    0    2    6    4    1]\n",
            " [   0    0    3  992    2    4    0    3    3    3]\n",
            " [   1    0    1    1  966    0    4    1    1    7]\n",
            " [   2    0    0    8    1  871    4    1    4    1]\n",
            " [   6    2    1    1    1    5  941    0    1    0]\n",
            " [   0    3    6    3    1    0    0 1009    1    5]\n",
            " [   2    0    1    3    5    4    1    3  953    2]\n",
            " [   2    2    0    3    7    4    0    4    1  986]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sdXS58IwWOXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "73ab4b67-a382-4935-866c-a0b54a696618"
      },
      "source": [
        "history.history.keys()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(len(history.history['val_accuracy'])), history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DySmpDX7n1CY",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}